{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87464792",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel #parallel computation\n",
    "import torch.optim as optim #optimizer \n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable #stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cdf8843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AItRBM-proof.pdf\t    boltzmann_machine.py   ml-100k.zip\r\n",
      "'boltzmann machine.ipynb'   ml-100k\t\t   ml-1m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a6f7fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.dat   ratings.dat  test_set.csv\t    Train_Test_Set_Creation.R\r\n",
      "ratings.csv  README\t  training_set.csv  users.dat\r\n"
     ]
    }
   ],
   "source": [
    "!ls ml-1m/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8df61ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1::Toy Story (1995)::Animation|Children's|Comedy\r\n",
      "2::Jumanji (1995)::Adventure|Children's|Fantasy\r\n",
      "3::Grumpier Old Men (1995)::Comedy|Romance\r\n",
      "4::Waiting to Exhale (1995)::Comedy|Drama\r\n",
      "5::Father of the Bride Part II (1995)::Comedy\r\n",
      "6::Heat (1995)::Action|Crime|Thriller\r\n",
      "7::Sabrina (1995)::Comedy|Romance\r\n",
      "8::Tom and Huck (1995)::Adventure|Children's\r\n",
      "9::Sudden Death (1995)::Action\r\n",
      "10::GoldenEye (1995)::Action|Adventure|Thriller\r\n"
     ]
    }
   ],
   "source": [
    "!head ml-1m/movies.dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8652f7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "movies = pd.read_csv(\"ml-1m/movies.dat\", sep=\"::\", header = None, engine=\"python\",encoding=\"latin-1\")\n",
    "#some movie titles have special characters and utf8 dont read them. Thats the encoding option\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbbef98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>3948</td>\n",
       "      <td>Meet the Parents (2000)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>3949</td>\n",
       "      <td>Requiem for a Dream (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>3950</td>\n",
       "      <td>Tigerland (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>3951</td>\n",
       "      <td>Two Family House (2000)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3882</th>\n",
       "      <td>3952</td>\n",
       "      <td>Contender, The (2000)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3883 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                   1                             2\n",
       "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4        5  Father of the Bride Part II (1995)                        Comedy\n",
       "...    ...                                 ...                           ...\n",
       "3878  3948             Meet the Parents (2000)                        Comedy\n",
       "3879  3949          Requiem for a Dream (2000)                         Drama\n",
       "3880  3950                    Tigerland (2000)                         Drama\n",
       "3881  3951             Two Family House (2000)                         Drama\n",
       "3882  3952               Contender, The (2000)                Drama|Thriller\n",
       "\n",
       "[3883 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9021783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6035</th>\n",
       "      <td>6036</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>32603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036</th>\n",
       "      <td>6037</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>76006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>6038</td>\n",
       "      <td>F</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>14706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6038</th>\n",
       "      <td>6039</td>\n",
       "      <td>F</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>01060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>6040</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>11106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6040 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1   2   3      4\n",
       "0        1  F   1  10  48067\n",
       "1        2  M  56  16  70072\n",
       "2        3  M  25  15  55117\n",
       "3        4  M  45   7  02460\n",
       "4        5  M  25  20  55455\n",
       "...    ... ..  ..  ..    ...\n",
       "6035  6036  F  25  15  32603\n",
       "6036  6037  F  45   1  76006\n",
       "6037  6038  F  56   1  14706\n",
       "6038  6039  F  45   0  01060\n",
       "6039  6040  M  25   6  11106\n",
       "\n",
       "[6040 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = pd.read_csv(\"ml-1m/users.dat\", sep=\"::\", header = None, engine=\"python\",encoding=\"latin-1\")\n",
    "users\n",
    "#user id, gender, age, code to user job, zip code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "282dd276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000204</th>\n",
       "      <td>6040</td>\n",
       "      <td>1091</td>\n",
       "      <td>1</td>\n",
       "      <td>956716541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000205</th>\n",
       "      <td>6040</td>\n",
       "      <td>1094</td>\n",
       "      <td>5</td>\n",
       "      <td>956704887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000206</th>\n",
       "      <td>6040</td>\n",
       "      <td>562</td>\n",
       "      <td>5</td>\n",
       "      <td>956704746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000207</th>\n",
       "      <td>6040</td>\n",
       "      <td>1096</td>\n",
       "      <td>4</td>\n",
       "      <td>956715648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000208</th>\n",
       "      <td>6040</td>\n",
       "      <td>1097</td>\n",
       "      <td>4</td>\n",
       "      <td>956715569</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000209 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1  2          3\n",
       "0           1  1193  5  978300760\n",
       "1           1   661  3  978302109\n",
       "2           1   914  3  978301968\n",
       "3           1  3408  4  978300275\n",
       "4           1  2355  5  978824291\n",
       "...       ...   ... ..        ...\n",
       "1000204  6040  1091  1  956716541\n",
       "1000205  6040  1094  5  956704887\n",
       "1000206  6040   562  5  956704746\n",
       "1000207  6040  1096  4  956715648\n",
       "1000208  6040  1097  4  956715569\n",
       "\n",
       "[1000209 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header = None, engine=\"python\",encoding=\"latin-1\")\n",
    "ratings\n",
    "#user, movie, rating (1 to 5), and a extra column that we dont care"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f0f701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### preparing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4afed40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79994</th>\n",
       "      <td>943</td>\n",
       "      <td>1067</td>\n",
       "      <td>2</td>\n",
       "      <td>875501756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79995</th>\n",
       "      <td>943</td>\n",
       "      <td>1074</td>\n",
       "      <td>4</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79996</th>\n",
       "      <td>943</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>888640250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79997</th>\n",
       "      <td>943</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>888640275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79998</th>\n",
       "      <td>943</td>\n",
       "      <td>1330</td>\n",
       "      <td>3</td>\n",
       "      <td>888692465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79999 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         1   1.1  5  874965758\n",
       "0        1     2  3  876893171\n",
       "1        1     3  4  878542960\n",
       "2        1     4  3  876893119\n",
       "3        1     5  3  889751712\n",
       "4        1     7  4  875071561\n",
       "...    ...   ... ..        ...\n",
       "79994  943  1067  2  875501756\n",
       "79995  943  1074  4  888640250\n",
       "79996  943  1188  3  888640250\n",
       "79997  943  1228  3  888640275\n",
       "79998  943  1330  3  888692465\n",
       "\n",
       "[79999 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv(\"ml-100k/u1.base\", delimiter=\"\\t\")\n",
    "training_set\n",
    "#user, movie, rating, timestamps (no relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "591bcb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#turning df in array\n",
    "training_set = np.array(training_set, dtype=\"int\")\n",
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3943ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set\n",
    "test_set = pd.read_csv(\"ml-100k/u1.test\", delimiter=\"\\t\")\n",
    "test_set = np.array(test_set, dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00a506e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,        10,         3, 875693118],\n",
       "       [        1,        12,         5, 878542960],\n",
       "       [        1,        14,         5, 874965706],\n",
       "       ...,\n",
       "       [      459,       934,         3, 879563639],\n",
       "       [      460,        10,         3, 882912371],\n",
       "       [      462,       682,         5, 886365231]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0047b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the number of users and movies, because then we will do \n",
    "# matrices of users and movies, were value will be the rate\n",
    "\n",
    "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0]))) # nb number\n",
    "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bbf74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data into an array with users in lines and movies \n",
    "# in columns. no ratings are equal to 0\n",
    "\n",
    "def convert(data):\n",
    "    #as we will use torch, we will do a 2d np array, we will do a\n",
    "    #list of list\n",
    "    new_data  = []\n",
    "    for id_users in range(1,nb_users+1): #upper bound is excludede, for this is +1\n",
    "        id_movies = data[:,1][data[:,0] == id_users]\n",
    "        id_ratings = data[:,2][data[:,0] == id_users]\n",
    "        ratings = np.zeros(nb_movies)\n",
    "        ratings[id_movies - 1] = id_ratings# -1 cause indexes start a 0\n",
    "        new_data.append(list(ratings)) #list of list as torch expect\n",
    "    return new_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a70c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f064c8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting list of list into torch tensors\n",
    "#tensor are  arrays that contains elements of a single datatype\n",
    "#is a multidimensional matrix, instead of np array, this is\n",
    "#a pythorch array much more efficient that np array for nn\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)\n",
    "\n",
    "#done the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea434aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boltzmann machine output are 1 or 0 \n",
    "#converting the ratings into binary ratings: 1 (liked) or 0 (not liked)\n",
    "\n",
    "training_set[training_set == 0] = -1\n",
    "#all zeroes in the original training set not exist (not rated), and\n",
    "#as the rating are 0 or 1, the original zeroes need another\n",
    "#value (not rating)\n",
    "training_set[training_set == 1] = 0\n",
    "training_set[training_set == 2] = 0\n",
    "training_set[training_set >= 3] = 1\n",
    "test_set[test_set == 0] = -1\n",
    "test_set[test_set == 1] = 0\n",
    "test_set[test_set == 2] = 0\n",
    "test_set[test_set >= 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e33f71a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the architecture of the neural network\n",
    "\n",
    "# a class with three functions, initialize the RBM, sample H that will\n",
    "# sample the probabilities of the hidden nodes given the visible nodes\n",
    "# and sample_v that will sample the probabilities of the visible nodes\n",
    "# given the hidden nodes\n",
    "class RBM():\n",
    "    def __init__(self, nv, nh):\n",
    "        #self is the object that will be created (for this and not \n",
    "        #global variables)\n",
    "        #nv: number of visible nodes\n",
    "        #nh: number of hidden nodes\n",
    "        \n",
    "        #initializing all the parameters to optimize during the \n",
    "        #RBM training process (weights and bias)\n",
    "        self.W = torch.randn(nh, nv) # weight, a torch tensor\n",
    "        #these weights are the parameters of the probabilities of the\n",
    "        #visible nodes given the hidden nodes\n",
    "        #rand initialize weights of probb P of the visible nodes \n",
    "        #given the hidden nodes (with size nh, nv)\n",
    "        #according normal distribution (mean 0 and variance 1)\n",
    "        \n",
    "        self.a = torch.randn(1, nh)\n",
    "        #bias for probb of hidden nodes given visible P(h,v)\n",
    "        self.b = torch.randn(1, nv)\n",
    "        #bias for probb of visible nodes given hidden P(v,h)\n",
    "        \n",
    "    #sampling hidden nodes according P(h,v) that is equal to the\n",
    "    #sigmoid activation function\n",
    "    \n",
    "    #first function of gibbs sampling\n",
    "    def sample_h(self, x): #x correspond to the visible neurons, v in P(h,v) \n",
    "        #computing the P(h,v), thats is the probb that hidden neuron\n",
    "        #equals 1 (liked) given value of the visible neuron that is actually\n",
    "        #our input vector of observations\n",
    "        \n",
    "        #P(H,v) = sigmoid activation function applied to wx + a (bias of\n",
    "        #hidden nodes, b is for visible)\n",
    "        wx = torch.mm(x, self.W.t()) #W^(t)*x\n",
    "        activation = wx + self.a.expand_as(wx) #wx + a = activation (what is inside activation function)\n",
    "        #expand_as(wx) is to do the minibatches\n",
    "        p_h_given_v = torch.sigmoid(activation) \n",
    "        \n",
    "        #we are doing a bernoulli RBM because we are predicting a binary\n",
    "        #outcome, and so what we will return also is some bernoulli\n",
    "        #samples of that distribution. This meand that right now P(h|v)\n",
    "        #is a vector of nh elements (probb of the Ith element is activated)\n",
    "        #given visible nodes, so now we want to sample the activation of\n",
    "        #each of this nodes  (yes or not), and taking as example\n",
    "        #a 70% probb of activate neuron (0.7), we take a random number\n",
    "        #between 0 and 1, and if this random number is below 0.7, then\n",
    "        #we will activate the neuron, otherwise we will not activate\n",
    "        #the neuron, that how bernoulli sampling works\n",
    "\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    \n",
    "    \n",
    "    #similar to the previous, but now for P(v|h)\n",
    "    def sample_v(self, y): #y are hidden nodes\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    \n",
    "    #v0: vector of rating movies by one user\n",
    "    #vk: visible nodes obtained after k samplings\n",
    "    #ph0: vector of probb that at the 1rst iteration the hidden\n",
    "    #nodes are equal to one given the values of V0\n",
    "    #Phk: probb of hidden nodes after K samplings given the values\n",
    "    #of the visible nodes Vk\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        #aproximating RBM loglikehood gradient\n",
    "        #for the previous, the cotrastive divergence algorithm\n",
    "        #is a good option to train (comes with gibbs sampling)\n",
    "        \n",
    "        #optimizing weights to minimize energy as described the algorithm\n",
    "        #in the paper\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee0a484e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = len(training_set[0])\n",
    "nh = 100 #number of features that the RBM will be detect\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24e606ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.3222)\n",
      "epoch: 2 loss: tensor(0.2364)\n",
      "epoch: 3 loss: tensor(0.2460)\n",
      "epoch: 4 loss: tensor(0.2490)\n",
      "epoch: 5 loss: tensor(0.2467)\n",
      "epoch: 6 loss: tensor(0.2463)\n",
      "epoch: 7 loss: tensor(0.2482)\n",
      "epoch: 8 loss: tensor(0.2453)\n",
      "epoch: 9 loss: tensor(0.2472)\n",
      "epoch: 10 loss: tensor(0.2463)\n"
     ]
    }
   ],
   "source": [
    "#training the RBM\n",
    "nb_epoch = 10\n",
    "#we will update the weights after the observations of each batch \n",
    "#passed through the network, and in the end we will get our visible \n",
    "#nodes with the new ratings for the movies that were not originally\n",
    "#rated\n",
    "for epoch in range(1, nb_epoch + 1): \n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, nb_users - batch_size, batch_size):\n",
    "        vk = training_set[id_user : id_user + batch_size]\n",
    "        v0 = training_set[id_user : id_user + batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b66a388a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.2406)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"## Testing the RBM\"\"\"\n",
    "\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    v = training_set[id_user:id_user+1] #we do not replace, cause are visible nodes obtained after k samplings\n",
    "    vt = test_set[id_user:id_user+1] # original rating in the test set\n",
    "    #we actually need to keep the training set, cause is the input \n",
    "    #that will be used to activate hidden neurons to get the output.\n",
    "    #right now the training set contains the ratings of training set\n",
    "    #and it does not contain the answers of the test set, but by using the inputs\n",
    "    #of the training set we will activate neurons of the RBM to predict\n",
    "    #the ratings of the movies that were not rated yet\n",
    "    #and that is the ratings of the test set. So we need this as input to\n",
    "    #get the predicted ratings of the test set\n",
    "    \n",
    "    \n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
